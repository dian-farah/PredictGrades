---
title: "Students' Grades Prediction"
output: html_notebook
---

The data used in this analysis is from https://www.kaggle.com/aljarah/xAPI-Edu-Data.

# attaching relevant libraries
```{r}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(tree)
library(caret)
library(randomForest)
```

# Data Exploration

```{r}
grades <- read.csv("xAPI-Edu-Data.csv", stringsAsFactors = T)
grades$Class <- factor(grades$Class, levels = c("L", "M", "H"))
head(grades, 10)
dplyr::nrows(grades)
```

```{r}
summary(grades)
```

```{r}
glimpse(grades)
```


```{r}
anyNA(grades)
```

```{r}
#what is value
library(reshape2)

grades2 <- grades %>%
  dplyr::select(raisedhands, VisITedResources, AnnouncementsView, Discussion, Class)
grades2_long <- reshape2::melt(grades2)
```

```{r}
#what is value - rename value
ggplot(grades2_long,aes(x= Class,y=value))+
  geom_boxplot(aes(fill=variable)) +
  ggtitle("Frequency of raised hands, visited resources, viewed announcements, & participate in discussions for each Grade") +
  theme(plot.title = element_text(size = 8, face="bold"))+
  xlab("Grades") +
  ylab("Frequency")
```

```{r}
#distribution of raisedhands
dist1 <- ggplot(data=grades2, aes(raisedhands)) + 
  geom_histogram(bins=30) +
  ggtitle("Distribution of raised hands")
```

```{r}
dist2 <- ggplot(data=grades2, aes(VisITedResources)) + 
  geom_histogram(bins=30) +
  ggtitle("Distribution of visited resources")
```

```{r}
dist3 <- ggplot(data=grades2, aes(AnnouncementsView)) + 
  geom_histogram(bins=30) +
  ggtitle("Distribution of view announcements")
```

```{r}
dist4 <- ggplot(data=grades2, aes(Discussion)) + 
  geom_histogram(bins=30) +
  ggtitle("Distribution of discussion participation")
```


```{r}
grid.arrange(dist1, dist2, dist3, dist4, nrow=2)
```


```{r}
ggplot(grades, aes(x=StudentAbsenceDays, fill=StudentAbsenceDays))+
  geom_bar() +
  facet_wrap(~Class)
```

```{r}
ggplot(grades, aes(x=StageID, fill=StageID))+
  geom_bar() +
  facet_wrap(~Class)
```

```{r}
ggplot(grades, aes(fill=Class, x=NationalITy))+
  geom_bar(position="stack") +
  coord_flip()
```

```{r}
ggplot(grades, aes(fill=ParentschoolSatisfaction, x=NationalITy))+
  geom_bar(position="stack") +
  coord_flip()
```

```{r}
ggplot(grades, aes(x=ParentschoolSatisfaction, fill=ParentschoolSatisfaction))+
  geom_bar() +
  facet_wrap(~Class)
```

```{r}
ggplot(grades, aes(x=Topic))+
  geom_bar() +
  coord_flip()
```

```{r}
ggplot(grades, aes(fill=Topic, x=Class))+
  geom_bar(position="stack")
```

```{r}
ggplot(grades, aes(fill=Class, x=Topic))+
  geom_bar(position="stack") +
  coord_flip()
```

# Predictive modelling
```{r}
#sample data 70%
RNGkind(sample.kind = "Rounding")
set.seed(123)
sample_index <- sample(1:nrow(grades), size = floor(0.70*nrow(grades)), replace = F)
train <- grades[sample_index,]
test <- grades[-sample_index,]
grades_actual <- test$Class
dim(train)
```

# Decision Tree ~ all features
```{r}
#create the tree
tree_grades <- tree(Class~., train)
summary(tree_grades)
plot(tree_grades)
title("Regression Tree to Predict Class Grades")
text(tree_grades, pretty=0)

#performance measurement
predict_grades1 <- predict(tree_grades, newdata=test, type="class")
grades_actual <- test$Class
confusionMatrix(predict_grades1, grades_actual, mode='everything')
```

```{r}
#prune the tree using cross-validation
cv_grades <- cv.tree(tree_grades, FUN=prune.misclass)
optimal_nodes <- cv_grades$size[which.min(cv_grades$dev)]
prune_grades <- prune.misclass(tree_grades, best = optimal_nodes)
summary(prune_grades)
plot(prune_grades)
title("Pruned Tree to Predict Class Grades")
text(prune_grades, pretty=0)

#performance measurement
predict_grades2 <- predict(prune_grades, newdata=test, type="class")
confusionMatrix(predict_grades2, grades_actual, mode='everything')
```
# Decision Tree ~ StudentAbsenceDays, raisedhands, VisITedResources, AnnouncementsView, Discussion, Relation, PlaceofBirth, Topic, GradeID
```{r}
grades_f1 <- grades %>%
  dplyr::select(StudentAbsenceDays, raisedhands, VisITedResources, AnnouncementsView, Discussion, Relation, PlaceofBirth, Topic, GradeID, Class)

head(grades_f1)
```

```{r}
#sample data 70%
RNGkind(sample.kind = "Rounding")
set.seed(123)
sample_index <- sample(1:nrow(grades_f1), size = floor(0.70*nrow(grades_f1)), replace = F)
trainf1 <- grades_f1[sample_index,]
testf1 <- grades_f1[-sample_index,]
```

```{r}
#create the tree
tree_gradesf1 <- tree(Class~., trainf1)
summary(tree_gradesf1)
plot(tree_grades)
title("Regression Tree to Predict Class Grades")
text(tree_gradesf1, pretty=0)

#prune the tree using cross-validation
cv_gradesf1 <- cv.tree(tree_gradesf1, FUN=prune.misclass)
optimal_nodesf1 <- cv_gradesf1$size[which.min(cv_gradesf1$dev)]
prune_gradesf1 <- prune.misclass(tree_gradesf1, best = optimal_nodesf1)
summary(prune_gradesf1)
plot(prune_gradesf1)
title("Pruned Tree to Predict Class Grades")
text(prune_gradesf1, pretty=0)

#performance measurement
predict_gradesf1 <- predict(prune_gradesf1, newdata=testf1, type="class")
grades_actualf1 <- testf1$Class
confusionMatrix(predict_gradesf1, grades_actualf1, mode='everything')
```

# Bagging and Random Forest ~ all features
```{r}
RNGkind(sample.kind = "Rounding")
set.seed(123)
bag_grades <- randomForest(Class~., data=train, importance=TRUE)
bag_grades

predict_grades3 <- predict(bag_grades, newdata=test)
importance(bag_grades, type=1, scale = F)
```

```{r}
#remove Semester
grades_f2 <- grades %>%
  dplyr::select(-c(Semester))

```

```{r}
RNGkind(sample.kind = "Rounding")
set.seed(123)

sample_index <- sample(1:nrow(grades_f2), size = floor(0.70*nrow(grades_f2)), replace = F)
train <- grades_f2[sample_index,]
test <- grades_f2[-sample_index,]

bag_grades1 <- randomForest(Class~., data=train, importance=TRUE)
bag_grades1

importance(bag_grades1, type=1, scale = F)
varImpPlot(bag_grades1)
```

```{r}
#Remove StudentAbsenceDays

RNGkind(sample.kind = "Rounding")
set.seed(123)

bag_grades2 <- randomForest(Class~.-StudentAbsenceDays, data=train, importance=TRUE)
bag_grades2

importance(bag_grades1)
varImpPlot(bag_grades1)
```
